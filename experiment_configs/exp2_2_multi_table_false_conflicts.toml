# Experiment 2.2: Multi-Table Saturation - False Conflicts Only
#
# Research Question 2a: Understand how table count affects throughput
#
# Setup:
# - Multiple tables with table-level conflicts (num_groups = num_tables)
# - All conflicts are "false" (version changed but no overlapping data)
# - Transactions access 2-3 tables on average (ntable.zipf = 1.5)
# - Infinitely fast catalog (T_CAS = 1ms, T_METADATA_ROOT = 1ms)
# - Realistic storage latencies for manifest lists/files
#
# Hypothesis:
# - More tables → less contention → higher saturation point
# - But multi-table transactions read more manifest lists
# - Parallelism limit (MAX_PARALLEL = 4) becomes bottleneck
#
# Expected Results:
# - More tables reduce contention (fewer transactions touch same tables)
# - But manifest list reading cost scales with number of tables
# - Net effect depends on workload skew (seltbl.zipf)
#
# How to Run:
# Sweep both num_tables and inter_arrival.scale:
#   num_tables = [1, 2, 5, 10, 20, 50]
#   inter_arrival.scale = [10, 20, 50, 100, 200, 500, 1000, 2000, 5000]
#
# IMPORTANT: Set num_groups = num_tables for table-level conflicts
#
# For each combination, run multiple seeds:
#   python -m icecap.main experiment_configs/exp2_2_multi_table_false_conflicts.toml

[simulation]
duration_ms = 3600000  # 1 hour (extended for stable statistics)
output_path = "results.parquet"
# seed = 42  # Uncomment to set specific seed, or leave unset for random

[experiment]
label = "exp2_2_multi_table_false"

[catalog]
# **SWEEP THIS PARAMETER** to study scaling with table count
num_tables = 10  # MODIFY THIS: 1, 2, 5, 10, 20, 50

# IMPORTANT: Set num_groups = num_tables for table-level conflicts
# This means transactions only conflict if they touch the same tables
num_groups = 10  # MODIFY THIS: must equal num_tables

[transaction]
retry = 10

# Transaction runtime (lognormal distribution)
# Realistic Iceberg transaction durations: 30s minimum, 3min mean
runtime.min = 30000   # 30 seconds
runtime.mean = 180000  # 3 minutes
runtime.sigma = 1.5

# Inter-arrival time distribution
# **SWEEP THIS PARAMETER** to vary offered load
inter_arrival.distribution = "exponential"
inter_arrival.scale = 500.0  # ~2 txn/sec (MODIFY THIS FOR LOAD SWEEP)

# Multi-table workload: transactions access 2-3 tables on average
ntable.zipf = 1.5  # Lower = more tables per transaction
seltbl.zipf = 1.4  # Which tables selected (lower = more uniform)
seltblw.zipf = 1.2  # Tables written vs read

# Conflict resolution: FALSE CONFLICTS ONLY
real_conflict_probability = 0.0  # All conflicts are false

# For real conflicts (not used in this experiment)
conflicting_manifests.distribution = "exponential"
conflicting_manifests.mean = 3.0
conflicting_manifests.min = 1
conflicting_manifests.max = 10

[storage]
# Parallelism limit for manifest operations during conflict resolution
max_parallel = 4

# Minimum latency for any storage operation (ms)
min_latency = 1

# ===== INFINITELY FAST CATALOG =====
# Near-instant catalog operations to isolate conflict resolution costs
T_CAS.mean = 1
T_CAS.stddev = 0.1

T_METADATA_ROOT.read.mean = 1
T_METADATA_ROOT.read.stddev = 0.1
T_METADATA_ROOT.write.mean = 1
T_METADATA_ROOT.write.stddev = 0.1

# ===== REALISTIC STORAGE LATENCIES =====
# Typical S3 performance
T_MANIFEST_LIST.read.mean = 50
T_MANIFEST_LIST.read.stddev = 5
T_MANIFEST_LIST.write.mean = 60
T_MANIFEST_LIST.write.stddev = 6

T_MANIFEST_FILE.read.mean = 50
T_MANIFEST_FILE.read.stddev = 5
T_MANIFEST_FILE.write.mean = 60
T_MANIFEST_FILE.write.stddev = 6
