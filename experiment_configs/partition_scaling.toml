# Partition Scaling Analysis
#
# Models how throughput scales with number of partitions.
# More partitions = less conflict probability = higher throughput
#
# Sweep parameters:
# - num_partitions: [10, 25, 50, 100, 200, 500]
# - inter_arrival.scale: [50, 100, 200]
#
# Expected insight: Diminishing returns as partition count increases

[simulation]
duration_ms = 3600000  # 1 hour
output_path = "results.parquet"

[experiment]
label = "partition_scaling"

[catalog]
num_tables = 1
num_groups = 1
table_metadata_inlined = true

[partition]
enabled = true
num_partitions = 100  # SWEEP THIS: [10, 25, 50, 100, 200, 500]
partitions_per_txn_mean = 3.0
partitions_per_txn_max = 10

[partition.selection]
distribution = "zipf"
zipf_alpha = 1.5

[transaction]
retry = 10
runtime.min = 30000    # 30 seconds minimum
runtime.mean = 180000  # 3 minutes mean
runtime.sigma = 1.5

inter_arrival.distribution = "exponential"
inter_arrival.scale = 100.0  # SWEEP THIS: [50, 100, 200]

real_conflict_probability = 0.0

conflicting_manifests.distribution = "exponential"
conflicting_manifests.mean = 3.0
conflicting_manifests.min = 1
conflicting_manifests.max = 10

[storage]
provider = "s3x"
max_parallel = 4
min_latency = 1
